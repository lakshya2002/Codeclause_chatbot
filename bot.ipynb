{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the utilites\n",
    "import nltk\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "from scipy.sparse import vstack\n",
    "import json\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow as tf \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['!','?','#','.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 'greeting',\n",
       "  'patterns': ['Greetings',\n",
       "   'Hey, chatbot',\n",
       "   'Hi',\n",
       "   'Hi there',\n",
       "   'How are you',\n",
       "   'Is anyone there?',\n",
       "   'Hey',\n",
       "   'Hola',\n",
       "   'Hello',\n",
       "   'Good day'],\n",
       "  'responses': ['Hello, thanks for asking',\n",
       "   'Good to see you again',\n",
       "   'Hi there, how can I help?',\n",
       "   \"Hey, what's up?\",\n",
       "   \"Hello! I'm here to help you. What can I do for you today?\"],\n",
       "  'context': []},\n",
       " {'tag': 'goodbye',\n",
       "  'patterns': ['Bye',\n",
       "   'See you later',\n",
       "   'Goodbye',\n",
       "   'Nice chatting to you, bye',\n",
       "   'Till next time',\n",
       "   'Catch you later',\n",
       "   'See you soon',\n",
       "   'Goodnight'],\n",
       "  'responses': ['See you!',\n",
       "   'Goodbye! It was a pleasure assisting you',\n",
       "   'Have a nice day',\n",
       "   'Bye! Come back again soon.',\n",
       "   'Goodbye! Have a great day!',\n",
       "   'Goodbye! Feel free to return if you have more questions',\n",
       "   \"Farewell! If you need anything else, don't hesitate to ask\",\n",
       "   \"Take care! If you have more questions, I'll be here to help.\"],\n",
       "  'context': []},\n",
       " {'tag': 'thanks',\n",
       "  'patterns': ['Thanks',\n",
       "   'Thank you',\n",
       "   \"That's helpful\",\n",
       "   'Awesome, thanks',\n",
       "   'Thanks for helping me',\n",
       "   'Thank you very much',\n",
       "   'I appreciate it',\n",
       "   'Thanks for your time/help',\n",
       "   \"You're great, thanks!\"],\n",
       "  'responses': ['Happy to help!',\n",
       "   'Any time!',\n",
       "   'My pleasure',\n",
       "   'Glad I could assist!',\n",
       "   \"I'm here to help you anytime\",\n",
       "   'Thank you for using our service!'],\n",
       "  'context': []},\n",
       " {'tag': 'noanswer',\n",
       "  'patterns': [],\n",
       "  'responses': [\"Sorry, can't understand you\",\n",
       "   'Please give me more info',\n",
       "   'Not sure I understand'],\n",
       "  'context': []},\n",
       " {'tag': 'options',\n",
       "  'patterns': ['How you could help me?',\n",
       "   'What you can do?',\n",
       "   'What help you provide?',\n",
       "   'How you can be helpful?',\n",
       "   'What support is offered'],\n",
       "  'responses': ['I can guide you if you have any query about Our Company CodeClause',\n",
       "   'I can give you info about the services and internships provided by codeclause.com'],\n",
       "  'context': []},\n",
       " {'tag': 'internships',\n",
       "  'patterns': ['Where to apply for internship?',\n",
       "   'Internships offered',\n",
       "   'How to apply for an internship?',\n",
       "   'How can I apply for the internship?',\n",
       "   'How can I get more information about the internships?'],\n",
       "  'responses': ['You can check our page on LinkedIn where you can find a post about how to apply to the internship',\n",
       "   {'OR Check this link': 'https://codeclause.com/careers.html to apply for the internship'}],\n",
       "  'context': []},\n",
       " {'tag': 'internships duration',\n",
       "  'patterns': ['How long the internship can be?',\n",
       "   'What is the duration of the internship?'],\n",
       "  'responses': ['The duration of the internship is one month',\n",
       "   'one month',\n",
       "   'only one month'],\n",
       "  'context': []},\n",
       " {'tag': 'internships fields',\n",
       "  'patterns': ['How many fields are there?',\n",
       "   'Which field that the internship concerns about?',\n",
       "   'Tell me about internship domains',\n",
       "   'internship domains'],\n",
       "  'responses': [{'There are many fields like': None},\n",
       "   'Data & Analytics,',\n",
       "   'Automation AI,',\n",
       "   'IoT Services,',\n",
       "   'Web Designing,',\n",
       "   'Web Application Development,',\n",
       "   'Mobile Application Development,',\n",
       "   'Software Development,',\n",
       "   'Digital Marketing,',\n",
       "   'Software Testing,',\n",
       "   'Quality Assurance services,',\n",
       "   'and many more.'],\n",
       "  'context': []},\n",
       " {'tag': 'About CodeClause',\n",
       "  'patterns': ['About codeclause',\n",
       "   'What is codeclause?',\n",
       "   'Services offered',\n",
       "   'What is codeclause internship?',\n",
       "   'codeclause',\n",
       "   'What is CodeClause?',\n",
       "   'What about CodeClause?',\n",
       "   'What is codeclause?',\n",
       "   'What about CodeClause?'],\n",
       "  'responses': ['CodeClause aspires to be the global sourcing choice of the world market and revolutionizes the way service processes function.',\n",
       "   'To reach out to the common people across the globe and make Information Technology a tool for the “MASS” along with the tool for the “CLASS”.',\n",
       "   'Creating innovative IT solutions and providing IT-enabled services to delight customers worldwide and build Relationships based on Trust, Values and Professionalism.',\n",
       "   'CodeClause has industry-specific software expertise in Technology, Financial, Healthcare, Media, Manufacturing, and many other sectors.',\n",
       "   'The company specializes in offering Data & Analytics,',\n",
       "   'Automation AI,',\n",
       "   'IoT Services,',\n",
       "   'Web Designing,',\n",
       "   'Web Application Development,',\n",
       "   'Mobile Application Development,',\n",
       "   'Software Development,',\n",
       "   'Digital Marketing,',\n",
       "   'Software Testing,',\n",
       "   'Quality Assurance services,',\n",
       "   'and many more.',\n",
       "   'We offer reliable, efficient delivery with high-caliber engineers & finely-tuned software development processes.',\n",
       "   'We Believe In Leadership to lead the technology to build a better future Integrity to follow truth and be real Accountability for our every commitment.',\n",
       "   'We Imagine, We Engineer, We Modernize, We Manage'],\n",
       "  'context': []},\n",
       " {'tag': 'offer_letter',\n",
       "  'patterns': ['Applied for internship',\n",
       "   'I have applied for internship',\n",
       "   'When will I receive my offer letter?',\n",
       "   'offer letter not received'],\n",
       "  'responses': [\"You will get your offer letter on mail around starting week of the month for which you've applied for the internship\"],\n",
       "  'context': []},\n",
       " {'tag': 'Contact',\n",
       "  'patterns': ['How can I contact you?',\n",
       "   'How can I contact codeclause?',\n",
       "   'How can I contact CodeClause?',\n",
       "   'How can I get in touch with you?',\n",
       "   'How can I get in touch with CodeClause?',\n",
       "   'How can I get in touch with codeclause?'],\n",
       "  'responses': [{'Contact us': None},\n",
       "   {'Address': '401 Shreenath Complex'},\n",
       "   '4th Floor',\n",
       "   'Near Polyhub FoodCourt',\n",
       "   'Vadgaon Pune, India.',\n",
       "   {'Phone': '+91 7030020973.'},\n",
       "   {'Email': 'official@codeclause.com.'},\n",
       "   {'Website': 'https://internship.codeclause.com/'}],\n",
       "  'context': []}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the intents.yml file\n",
    "with open('intents.yml', 'r',encoding='utf-8') as file:\n",
    "    yaml_data = yaml.safe_load(file)\n",
    "intents = yaml_data['intents']\n",
    "intents    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tokenization</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use spacy for Tokenzation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        # Tokenize each word and perform lemmatization\n",
    "        tokenized_words =  nlp(pattern)\n",
    "        words.extend(tokenized_words)\n",
    "        # Add documents to the corpus\n",
    "        documents.append((tokenized_words, intent['tag']))\n",
    "        # Add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Greetings, Hey, ,, chatbot, Hi, Hi, there, How, are, you, Is, anyone, there, ?, Hey, Hola, Hello, Good, day, Bye, See, you, later, Goodbye, Nice, chatting, to, you, ,, bye, Till, next, time, Catch, you, later, See, you, soon, Goodnight, Thanks, Thank, you, That, 's, helpful, Awesome, ,, thanks, Thanks, for, helping, me, Thank, you, very, much, I, appreciate, it, Thanks, for, your, time, /, help, You, 're, great, ,, thanks, !, How, you, could, help, me, ?, What, you, can, do, ?, What, help, you, provide, ?, How, you, can, be, helpful, ?, What, support, is, offered, Where, to, apply, for, internship, ?, Internships, offered, How, to, apply, for, an, internship, ?, How, can, I, apply, for, the, internship, ?, How, can, I, get, more, information, about, the, internships, ?, How, long, the, internship, can, be, ?, What, is, the, duration, of, the, internship, ?, How, many, fields, are, there, ?, Which, field, that, the, internship, concerns, about, ?, Tell, me, about, internship, domains, internship, domains, About, codeclause, What, is, codeclause, ?, Services, offered, What, is, codeclause, internship, ?, codeclause, What, is, CodeClause, ?, What, about, CodeClause, ?, What, is, codeclause, ?, What, about, CodeClause, ?, Applied, for, internship, I, have, applied, for, internship, When, will, I, receive, my, offer, letter, ?, offer, letter, not, received, How, can, I, contact, you, ?, How, can, I, contact, codeclause, ?, How, can, I, contact, CodeClause, ?, How, can, I, get, in, touch, with, you, ?, How, can, I, get, in, touch, with, CodeClause, ?, How, can, I, get, in, touch, with, codeclause, ?]\n",
      "length 262\n"
     ]
    }
   ],
   "source": [
    "print(words)\n",
    "print( 'length',len(words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Lemmatization</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['greeting',\n",
       " 'hey',\n",
       " ',',\n",
       " 'chatbot',\n",
       " 'hi',\n",
       " 'hi',\n",
       " 'there',\n",
       " 'how',\n",
       " 'be',\n",
       " 'you',\n",
       " 'be',\n",
       " 'anyone',\n",
       " 'there',\n",
       " '?',\n",
       " 'hey',\n",
       " 'Hola',\n",
       " 'hello',\n",
       " 'good',\n",
       " 'day',\n",
       " 'bye',\n",
       " 'see',\n",
       " 'you',\n",
       " 'later',\n",
       " 'Goodbye',\n",
       " 'Nice',\n",
       " 'chatting',\n",
       " 'to',\n",
       " 'you',\n",
       " ',',\n",
       " 'bye',\n",
       " 'till',\n",
       " 'next',\n",
       " 'time',\n",
       " 'catch',\n",
       " 'you',\n",
       " 'later',\n",
       " 'see',\n",
       " 'you',\n",
       " 'soon',\n",
       " 'Goodnight',\n",
       " 'thank',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'that',\n",
       " 'be',\n",
       " 'helpful',\n",
       " 'Awesome',\n",
       " ',',\n",
       " 'thank',\n",
       " 'thank',\n",
       " 'for',\n",
       " 'help',\n",
       " 'I',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'very',\n",
       " 'much',\n",
       " 'I',\n",
       " 'appreciate',\n",
       " 'it',\n",
       " 'thank',\n",
       " 'for',\n",
       " 'your',\n",
       " 'time',\n",
       " '/',\n",
       " 'help',\n",
       " 'you',\n",
       " 'be',\n",
       " 'great',\n",
       " ',',\n",
       " 'thank',\n",
       " '!',\n",
       " 'how',\n",
       " 'you',\n",
       " 'could',\n",
       " 'help',\n",
       " 'I',\n",
       " '?',\n",
       " 'what',\n",
       " 'you',\n",
       " 'can',\n",
       " 'do',\n",
       " '?',\n",
       " 'what',\n",
       " 'help',\n",
       " 'you',\n",
       " 'provide',\n",
       " '?',\n",
       " 'how',\n",
       " 'you',\n",
       " 'can',\n",
       " 'be',\n",
       " 'helpful',\n",
       " '?',\n",
       " 'what',\n",
       " 'support',\n",
       " 'be',\n",
       " 'offer',\n",
       " 'where',\n",
       " 'to',\n",
       " 'apply',\n",
       " 'for',\n",
       " 'internship',\n",
       " '?',\n",
       " 'internship',\n",
       " 'offer',\n",
       " 'how',\n",
       " 'to',\n",
       " 'apply',\n",
       " 'for',\n",
       " 'an',\n",
       " 'internship',\n",
       " '?',\n",
       " 'how',\n",
       " 'can',\n",
       " 'I',\n",
       " 'apply',\n",
       " 'for',\n",
       " 'the',\n",
       " 'internship',\n",
       " '?',\n",
       " 'how',\n",
       " 'can',\n",
       " 'I',\n",
       " 'get',\n",
       " 'more',\n",
       " 'information',\n",
       " 'about',\n",
       " 'the',\n",
       " 'internship',\n",
       " '?',\n",
       " 'how',\n",
       " 'long',\n",
       " 'the',\n",
       " 'internship',\n",
       " 'can',\n",
       " 'be',\n",
       " '?',\n",
       " 'what',\n",
       " 'be',\n",
       " 'the',\n",
       " 'duration',\n",
       " 'of',\n",
       " 'the',\n",
       " 'internship',\n",
       " '?',\n",
       " 'how',\n",
       " 'many',\n",
       " 'field',\n",
       " 'be',\n",
       " 'there',\n",
       " '?',\n",
       " 'which',\n",
       " 'field',\n",
       " 'that',\n",
       " 'the',\n",
       " 'internship',\n",
       " 'concern',\n",
       " 'about',\n",
       " '?',\n",
       " 'tell',\n",
       " 'I',\n",
       " 'about',\n",
       " 'internship',\n",
       " 'domain',\n",
       " 'internship',\n",
       " 'domain',\n",
       " 'about',\n",
       " 'codeclause',\n",
       " 'what',\n",
       " 'be',\n",
       " 'codeclause',\n",
       " '?',\n",
       " 'service',\n",
       " 'offer',\n",
       " 'what',\n",
       " 'be',\n",
       " 'codeclause',\n",
       " 'internship',\n",
       " '?',\n",
       " 'codeclause',\n",
       " 'what',\n",
       " 'be',\n",
       " 'CodeClause',\n",
       " '?',\n",
       " 'what',\n",
       " 'about',\n",
       " 'CodeClause',\n",
       " '?',\n",
       " 'what',\n",
       " 'be',\n",
       " 'codeclause',\n",
       " '?',\n",
       " 'what',\n",
       " 'about',\n",
       " 'CodeClause',\n",
       " '?',\n",
       " 'apply',\n",
       " 'for',\n",
       " 'internship',\n",
       " 'I',\n",
       " 'have',\n",
       " 'apply',\n",
       " 'for',\n",
       " 'internship',\n",
       " 'when',\n",
       " 'will',\n",
       " 'I',\n",
       " 'receive',\n",
       " 'my',\n",
       " 'offer',\n",
       " 'letter',\n",
       " '?',\n",
       " 'offer',\n",
       " 'letter',\n",
       " 'not',\n",
       " 'receive',\n",
       " 'how',\n",
       " 'can',\n",
       " 'I',\n",
       " 'contact',\n",
       " 'you',\n",
       " '?',\n",
       " 'how',\n",
       " 'can',\n",
       " 'I',\n",
       " 'contact',\n",
       " 'codeclause',\n",
       " '?',\n",
       " 'how',\n",
       " 'can',\n",
       " 'I',\n",
       " 'contact',\n",
       " 'CodeClause',\n",
       " '?',\n",
       " 'how',\n",
       " 'can',\n",
       " 'I',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'you',\n",
       " '?',\n",
       " 'how',\n",
       " 'can',\n",
       " 'I',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'CodeClause',\n",
       " '?',\n",
       " 'how',\n",
       " 'can',\n",
       " 'I',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'codeclause',\n",
       " '?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_words = [token.lemma_ for token in nlp(\" \".join(map(str, words)))]\n",
    "# Update the 'words' list with the lemmatized forms\n",
    "words = lemmatized_words\n",
    "print(len(words))\n",
    "words\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_sentence = \" \".join(lemmatized_words)\n",
    "doc = nlp(lemmatized_sentence)\n",
    "\n",
    "# Extract named entities from the lemmatized sentence\n",
    "named_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['About CodeClause',\n",
       " 'Contact',\n",
       " 'goodbye',\n",
       " 'greeting',\n",
       " 'internships',\n",
       " 'internships duration',\n",
       " 'internships fields',\n",
       " 'offer_letter',\n",
       " 'options',\n",
       " 'thanks']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classes = sorted(list(set(classes)))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 classes ['About CodeClause', 'Contact', 'goodbye', 'greeting', 'internships', 'internships duration', 'internships fields', 'offer_letter', 'options', 'thanks']\n"
     ]
    }
   ],
   "source": [
    "print (len(classes), \"classes\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 unique lemmatized words ['greeting', 'hey', ',', 'chatbot', 'hi', 'hi', 'there', 'how', 'be', 'you', 'be', 'anyone', 'there', '?', 'hey', 'Hola', 'hello', 'good', 'day', 'bye', 'see', 'you', 'later', 'Goodbye', 'Nice', 'chatting', 'to', 'you', ',', 'bye', 'till', 'next', 'time', 'catch', 'you', 'later', 'see', 'you', 'soon', 'Goodnight', 'thank', 'thank', 'you', 'that', 'be', 'helpful', 'Awesome', ',', 'thank', 'thank', 'for', 'help', 'I', 'thank', 'you', 'very', 'much', 'I', 'appreciate', 'it', 'thank', 'for', 'your', 'time', '/', 'help', 'you', 'be', 'great', ',', 'thank', '!', 'how', 'you', 'could', 'help', 'I', '?', 'what', 'you', 'can', 'do', '?', 'what', 'help', 'you', 'provide', '?', 'how', 'you', 'can', 'be', 'helpful', '?', 'what', 'support', 'be', 'offer', 'where', 'to', 'apply', 'for', 'internship', '?', 'internship', 'offer', 'how', 'to', 'apply', 'for', 'an', 'internship', '?', 'how', 'can', 'I', 'apply', 'for', 'the', 'internship', '?', 'how', 'can', 'I', 'get', 'more', 'information', 'about', 'the', 'internship', '?', 'how', 'long', 'the', 'internship', 'can', 'be', '?', 'what', 'be', 'the', 'duration', 'of', 'the', 'internship', '?', 'how', 'many', 'field', 'be', 'there', '?', 'which', 'field', 'that', 'the', 'internship', 'concern', 'about', '?', 'tell', 'I', 'about', 'internship', 'domain', 'internship', 'domain', 'about', 'codeclause', 'what', 'be', 'codeclause', '?', 'service', 'offer', 'what', 'be', 'codeclause', 'internship', '?', 'codeclause', 'what', 'be', 'CodeClause', '?', 'what', 'about', 'CodeClause', '?', 'what', 'be', 'codeclause', '?', 'what', 'about', 'CodeClause', '?', 'apply', 'for', 'internship', 'I', 'have', 'apply', 'for', 'internship', 'when', 'will', 'I', 'receive', 'my', 'offer', 'letter', '?', 'offer', 'letter', 'not', 'receive', 'how', 'can', 'I', 'contact', 'you', '?', 'how', 'can', 'I', 'contact', 'codeclause', '?', 'how', 'can', 'I', 'contact', 'CodeClause', '?', 'how', 'can', 'I', 'get', 'in', 'touch', 'with', 'you', '?', 'how', 'can', 'I', 'get', 'in', 'touch', 'with', 'CodeClause', '?', 'how', 'can', 'I', 'get', 'in', 'touch', 'with', 'codeclause', '?']\n"
     ]
    }
   ],
   "source": [
    "print (len(words), \"unique lemmatized words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 unique lemmatized words ['greeting', 'hey', ',', 'chatbot', 'hi', 'there', 'how', 'be', 'you', 'anyone', '?', 'Hola', 'hello', 'good', 'day', 'bye', 'see', 'later', 'Goodbye', 'Nice', 'chatting', 'to', 'till', 'next', 'time', 'catch', 'soon', 'Goodnight', 'thank', 'that', 'helpful', 'Awesome', 'for', 'help', 'I', 'very', 'much', 'appreciate', 'it', 'your', '/', 'great', '!', 'could', 'what', 'can', 'do', 'provide', 'support', 'offer', 'where', 'apply', 'internship', 'an', 'the', 'get', 'more', 'information', 'about', 'long', 'duration', 'of', 'many', 'field', 'which', 'concern', 'tell', 'domain', 'codeclause', 'service', 'CodeClause', 'have', 'when', 'will', 'receive', 'my', 'letter', 'not', 'contact', 'in', 'touch', 'with']\n"
     ]
    }
   ],
   "source": [
    "unique_words = []\n",
    "for x in words:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_words:\n",
    "            unique_words.append(x)\n",
    "            \n",
    "print (len(unique_words), \"unique lemmatized words\", unique_words)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 documents\n"
     ]
    }
   ],
   "source": [
    "# all possible sentences belonging to each class\n",
    "print (len(documents), \"documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Training data with  Intent classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for TF-IDF\n",
    "sentences = [\" \".join([token.text for token in pattern]) for pattern, tag in documents]\n",
    "labels = [tag for pattern, tag in documents]\n",
    "\n",
    "# sentences ----> contain all the possible ways of sentences input by user\n",
    "# labels --> labels will contain the corresponding intent tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['about', 'an', 'anyone', 'applied', 'apply', 'appreciate', 'are', 'awesome', 'be', 'bye', 'can', 'catch', 'chatbot', 'chatting', 'codeclause', 'concerns', 'contact', 'could', 'day', 'do', 'domains', 'duration', 'field', 'fields', 'for', 'get', 'good', 'goodbye', 'goodnight', 'great', 'greetings', 'have', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hola', 'how', 'in', 'information', 'internship', 'internships', 'is', 'it', 'later', 'letter', 'long', 'many', 'me', 'more', 'much', 'my', 'next', 'nice', 'not', 'of', 'offer', 'offered', 'provide', 're', 'receive', 'received', 'see', 'services', 'soon', 'support', 'tell', 'thank', 'thanks', 'that', 'the', 'there', 'till', 'time', 'to', 'touch', 'very', 'what', 'when', 'where', 'which', 'will', 'with', 'you', 'your']\n",
      "TF-IDF Matrix:\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.43745151 0.28354449 0.        ]\n",
      " [0.         0.         0.         ... 0.43533937 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.43533937 0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lakshya\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create an instance of TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Example text documents\n",
    "documents = sentences\n",
    "\n",
    "# Fit and transform the documents\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (words)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Print the feature names and TF-IDF matrix\n",
    "print(\"Feature Names:\", feature_names)\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.43745151, 0.28354449,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.43533937, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.43533937, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix = tfidf_matrix.toarray()\n",
    "tf_matrix\n",
    "# Initialize the vector object\n",
    "# vectorizer = TfidfVectorizer(lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit vectorizer on the sentences\n",
    "# tfidf_features = vectorizer.fit_transform(sentences)\n",
    "# tfidf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = vectorizer.get_feature_names()\n",
    "# print(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training=[]\n",
    "output_empty = [0]*len(classes)\n",
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'r' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\Code_clause\\Chatbot\\bot.ipynb Cell 26\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# output is a '0' for each tag and '1' for current tag (for each pattern)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m output_row \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(output_empty)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m output_row[classes\u001b[39m.\u001b[39;49mindex(doc[\u001b[39m1\u001b[39;49m])] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m training\u001b[39m.\u001b[39mappend([bag, output_row])\n",
      "\u001b[1;31mValueError\u001b[0m: 'r' is not in list"
     ]
    }
   ],
   "source": [
    "# create  a training set \n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # lemmatize each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [token.lemma_ for token in nlp(\" \".join(map(str, words)))]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    \n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    \n",
    "    training.append([bag, output_row])\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greet', 'hey', ',', 'chatbot', 'hi', 'hi', 'there', 'how', 'be', 'you', 'be', 'anyone', 'there', '?', 'hey', 'Hola', 'hello', 'good', 'day', 'bye', 'see', 'you', 'later', 'Goodbye', 'Nice', 'chatting', 'to', 'you', ',', 'bye', 'till', 'next', 'time', 'catch', 'you', 'later', 'see', 'you', 'soon', 'Goodnight', 'thank', 'thank', 'you', 'that', 'be', 'helpful', 'Awesome', ',', 'thank', 'thank', 'for', 'help', 'I', 'thank', 'you', 'very', 'much', 'I', 'appreciate', 'it', 'thank', 'for', 'your', 'time', '/', 'help', 'you', 'be', 'great', ',', 'thank', '!', 'how', 'you', 'could', 'help', 'I', '?', 'what', 'you', 'can', 'do', '?', 'what', 'help', 'you', 'provide', '?', 'how', 'you', 'can', 'be', 'helpful', '?', 'what', 'support', 'be', 'offer', 'where', 'to', 'apply', 'for', 'internship', '?', 'internship', 'offer', 'how', 'to', 'apply', 'for', 'an', 'internship', '?', 'how', 'can', 'I', 'apply', 'for', 'the', 'internship', '?', 'how', 'can', 'I', 'get', 'more', 'information', 'about', 'the', 'internship', '?', 'how', 'long', 'the', 'internship', 'can', 'be', '?', 'what', 'be', 'the', 'duration', 'of', 'the', 'internship', '?', 'how', 'many', 'field', 'be', 'there', '?', 'which', 'field', 'that', 'the', 'internship', 'concern', 'about', '?', 'tell', 'I', 'about', 'internship', 'domain', 'internship', 'domain', 'about', 'codeclause', 'what', 'be', 'codeclause', '?', 'service', 'offer', 'what', 'be', 'codeclause', 'internship', '?', 'codeclause', 'what', 'be', 'CodeClause', '?', 'what', 'about', 'CodeClause', '?', 'what', 'be', 'codeclause', '?', 'what', 'about', 'CodeClause', '?', 'apply', 'for', 'internship', 'I', 'have', 'apply', 'for', 'internship', 'when', 'will', 'I', 'receive', 'my', 'offer', 'letter', '?', 'offer', 'letter', 'not', 'receive', 'how', 'can', 'I', 'contact', 'you', '?', 'how', 'can', 'I', 'contact', 'codeclause', '?', 'how', 'can', 'I', 'contact', 'CodeClause', '?', 'how', 'can', 'I', 'get', 'in', 'touch', 'with', 'you', '?', 'how', 'can', 'I', 'get', 'in', 'touch', 'with', 'CodeClause', '?', 'how', 'can', 'I', 'get', 'in', 'touch', 'with', 'codeclause', '?']\n"
     ]
    }
   ],
   "source": [
    "print(pattern_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lakshya\\AppData\\Local\\Temp\\ipykernel_1944\\3934461316.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  training_set = np.array(training_set)\n"
     ]
    }
   ],
   "source": [
    "# Convert Training Set to Numpy Arrays:\n",
    "training_set = np.array(training_set)\n",
    "X_train = np.array(training_set[:, 0].tolist())\n",
    "y_train = np.array(training_set[:, 1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3844, 87)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Features (X_train):\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.43745151 0.28354449 0.        ]\n",
      " [0.         0.         0.         ... 0.43533937 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.43533937 0.         0.        ]]\n",
      "Intent Labels (y_train):\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF Features (X_train):\\n\", X_train)\n",
    "print(\"Intent Labels (y_train):\\n\", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create neural network model using the Keras framework with TensorFlow backend\n",
    "# This model is used for intent classification based on the TF-IDF features (train_x) and one-hot encoded intent labels (train_y).\n",
    "# model = Sequential()\n",
    "# model.add(Dense(128, input_shape=(X_train.shape[0],), activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(len(y_train[0]), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3844, 87)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\Code_clause\\Chatbot\\bot.ipynb Cell 34\u001b[0m in \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# stacked_sparse_matrix = vstack(X_train)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Convert the stacked sparse matrix to a dense NumPy array\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# dense_array = stacked_sparse_matrix.toarray()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Create the Keras Sequential model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_train\u001b[39m.\u001b[39mshape) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     X_train \u001b[39m=\u001b[39m X_train_tensor\u001b[39m.\u001b[39mreshape(x_train_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#X45sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name '_train' is not defined"
     ]
    }
   ],
   "source": [
    "# stacked_sparse_matrix = vstack(X_train)\n",
    "\n",
    "# Convert the stacked sparse matrix to a dense NumPy array\n",
    "# dense_array = stacked_sparse_matrix.toarray()\n",
    "\n",
    "# Create the Keras Sequential model\n",
    "if len(_train.shape) > 2:\n",
    "    X_train = X_train_tensor.reshape(x_train_tensor.shape[0], -1)\n",
    "else:\n",
    "    print(\"all ok\")    \n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(y_train[0]), activation='softmax'))\n",
    "\n",
    "# Compile the model with the optimizer you prefer\n",
    "sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Convert the dense array to a tensor using tf.convert_to_tensor\n",
    "x_train_tensor = tf.convert_to_tensor(dense_array, dtype=tf.float32)\n",
    "\n",
    "# Fit the model with the tensor input\n",
    "history = model.fit(x_train_tensor, y_train, epochs=200, batch_size=5, verbose=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('bot_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- model is successfully trained now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "import random\n",
    "from keras.models import load_model\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = load_model('bot_model.h5')\n",
    "# intents = json.loads(open('intents.yml').read())\n",
    "with open('intents.yml', 'r',encoding='utf-8') as file:\n",
    "    yaml_data = yaml.safe_load(file)\n",
    "intents = yaml_data['intents']  \n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dragon', 'fox', 'in', 'the', 'house', 'of', 'batiatus']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"dragon fox in the house of batiatus\"\n",
    "sentence_word = nltk.word_tokenize(doc)\n",
    "sentence_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(sentence):\n",
    "    # Tokenize the pattern - split into segments\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser','ner'])\n",
    "    sentenceWords = nlp(sentence)\n",
    "    # tem each word - create short form for word\n",
    "    sentenceWords = [token.lemma_ for token in nlp(\" \".join(map(str, sentenceWords)))]\n",
    "    # Update the 'words' list with the lemmatized forms\n",
    "    return sentenceWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer: 0 or 1 for each word in the vector that exists in the sentence\n",
    "def tfvectorise(sentence, vectorizer, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = pre_process(sentence)\n",
    "    # fitted\n",
    "    vectorizer.fit(sentence_words)\n",
    "    # TfidfVectorizer to transform the sentence into a TF-IDF vector\n",
    "    tfidf_vector = vectorizer.transform([sentence]).toarray()\n",
    "    if show_details:\n",
    "        print(\"TF-IDF Vector:\")\n",
    "        print(tfidf_vector)\n",
    "    return (np.array(tfidf_vector))\n",
    "\n",
    "\n",
    "\n",
    "# def tfvectorise(sentence, vectorizer, show_details=True):\n",
    "#     # tokenize the pattern\n",
    "#     sentence_words = pre_process(sentence)\n",
    "#     # fitted\n",
    "#     vectorizer.fit(sentence_words)\n",
    "#     # TfidfVectorizer to transform the sentence into a TF-IDF vector\n",
    "#     tfidf_vector = vectorizer.transform([sentence]).toarray().flatten()  # Reshape to (87,) array\n",
    "#     if show_details:\n",
    "#         print(\"TF-IDF Vector:\")\n",
    "#         print(tfidf_vector)\n",
    "#     return tfidf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "# doc = \"dragon in the house dragon  please help\"\n",
    "# tfvectorise(doc,vectorizer,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to predict the intent of a given sentence based on the trained model and TF-IDF vector of the sentence.\n",
    "# # The intent with the highest probability above the error threshold is considered the final prediction.\n",
    "# def predict_class(sentence, model):\n",
    "#     x = tfvectorise(sentence,vectorizer,show_details=False)\n",
    "#     res = model.predict(np.array([x]))[0]\n",
    "#     ERROR_THRESHOLD = 0.25\n",
    "#     results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "#     # sort by strength of probability\n",
    "#     results.sort(key=lambda x: x[1], reverse=True)\n",
    "#     return_list = []\n",
    "#     for r in results:\n",
    "#         return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "#     return return_list\n",
    "    \n",
    "    \n",
    "def predict_class(sentence, model):\n",
    "    x = tfvectorise(sentence, vectorizer, show_details=False)\n",
    "    res = model.predict(np.array([x]))[0]  # Reshape to (1, 87)\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a random response associated with the predicted intent.\n",
    "def getResponse(ints, intents_yml):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_yml['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(msg):\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling user input, processing it, and displaying the chatbot's response in the chat log window\n",
    "def send():\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
    "    \n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"Bot: \" + res + '\\n\\n')\n",
    "            \n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_chat():\n",
    "     name = input(\"Enter Your Name: \")\n",
    "     print(\"Welcome \" + name + \" to the Code Clause Bot Service! Let me know how can I help you?\\n\")\n",
    "     while True:\n",
    "         input_msg = str(input()).lower()\n",
    "         if input_msg.lower()==\"end\":\n",
    "             break\n",
    "         if input_msg.lower()== '' or input_msg.lower()== '*':\n",
    "             print('Please re-phrase your query!')\n",
    "             print(\"-\"*50)\n",
    "         else:\n",
    "             print(f\"Code Clause: {chatbot_response(input_msg)}\"+'\\n')\n",
    "             print(\"-\"*50)\n",
    "\n",
    "# start the chat bot\n",
    "start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_chat():\n",
    "     name = input(\"Enter Your Name: \")\n",
    "     print(\"Welcome \" + name + \" to the Code Clause Bot Service! Let me know how can I help you?\\n\")\n",
    "     while True:\n",
    "         input_msg = input(\"You: \").lower()\n",
    "         if input_msg == \"end\":\n",
    "             print(\"Chat ended.\")\n",
    "             break\n",
    "         if input_msg == '' or input_msg == '*':\n",
    "             print('Please re-phrase your query!')\n",
    "         else:\n",
    "             response = chatbot_response(input_msg)\n",
    "             print(f\"Code Clause: {response}\\n\")\n",
    "         print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome hi to the Code Clause Bot Service! Let me know how can I help you?\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Input 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 87, but received input with shape (None, 1)\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\Code_clause\\Chatbot\\bot.ipynb Cell 48\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m start_chat()\n",
      "\u001b[1;32mg:\\Code_clause\\Chatbot\\bot.ipynb Cell 48\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPlease re-phrase your query!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     response \u001b[39m=\u001b[39m chatbot_response(input_msg)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCode Clause: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m50\u001b[39m)\n",
      "\u001b[1;32mg:\\Code_clause\\Chatbot\\bot.ipynb Cell 48\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchatbot_response\u001b[39m(msg):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     ints \u001b[39m=\u001b[39m predict_class(msg, model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     res \u001b[39m=\u001b[39m getResponse(ints, intents)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "\u001b[1;32mg:\\Code_clause\\Chatbot\\bot.ipynb Cell 48\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_class\u001b[39m(sentence, model):\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     x \u001b[39m=\u001b[39m tfvectorise(sentence, vectorizer, show_details\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     res \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49marray([x]))[\u001b[39m0\u001b[39m]  \u001b[39m# Reshape to (1, 87)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     ERROR_THRESHOLD \u001b[39m=\u001b[39m \u001b[39m0.25\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Code_clause/Chatbot/bot.ipynb#Y113sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     results \u001b[39m=\u001b[39m [[i, r] \u001b[39mfor\u001b[39;00m i, r \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(res) \u001b[39mif\u001b[39;00m r \u001b[39m>\u001b[39m ERROR_THRESHOLD]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file7aaw1_gj.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Lakshya\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_2' (type Sequential).\n    \n    Input 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 87, but received input with shape (None, 1)\n    \n    Call arguments received by layer 'sequential_2' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "from tkinter import *\n",
    "import sys\n",
    "import os\n",
    "if os.environ.get('DISPLAY','')=='':\n",
    "  print('no DISPLAY found. Using: 0.0')\n",
    "  os.environ.__setitem__('DISPLAY',':0.0')\n",
    "base = Tk()\n",
    "base.title(\"Hello\")\n",
    "base.geometry(\"400x500\")\n",
    "base.resizable(width=FALSE, height=FALSE)\n",
    "#Create Chat window\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)\n",
    "\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "#Bind scrollbar to Chat window\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "\n",
    "#Create Button to send message\n",
    "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
    "                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
    "                    command= send )\n",
    "\n",
    "#Create the box to enter message\n",
    "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
    "#EntryBox.bind(\"<Return>\", send)\n",
    "\n",
    "\n",
    "#Place all components on the screen\n",
    "scrollbar.place(x=376,y=6, height=386)\n",
    "ChatLog.place(x=6,y=6, height=386, width=370)\n",
    "EntryBox.place(x=128, y=401, height=90, width=265)\n",
    "SendButton.place(x=6, y=401, height=90)\n",
    "\n",
    "base.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
